{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.103460393846035, Accuracy: 96.90666961669922, Test Loss: 0.07605160027742386, Test Accuracy: 97.43000030517578\n",
      "Running time:  120.63209509849548 seconds\n",
      "Epoch 2, Loss: 0.05090997368097305, Accuracy: 98.41333770751953, Test Loss: 0.05673982575535774, Test Accuracy: 98.41999816894531\n",
      "Running time:  121.20508003234863 seconds\n",
      "Epoch 3, Loss: 0.0391223169863224, Accuracy: 98.76333618164062, Test Loss: 0.03592681512236595, Test Accuracy: 98.81999969482422\n",
      "Running time:  122.74642729759216 seconds\n",
      "Epoch 4, Loss: 0.031126245856285095, Accuracy: 99.05333709716797, Test Loss: 0.03433534502983093, Test Accuracy: 98.94000244140625\n",
      "Running time:  119.95084857940674 seconds\n",
      "Epoch 5, Loss: 0.0250840000808239, Accuracy: 99.22166442871094, Test Loss: 0.039463531225919724, Test Accuracy: 98.76000213623047\n",
      "Running time:  118.77612853050232 seconds\n",
      "Epoch 6, Loss: 0.01952977664768696, Accuracy: 99.36000061035156, Test Loss: 0.03127724677324295, Test Accuracy: 98.97999572753906\n",
      "Running time:  118.97467303276062 seconds\n",
      "Epoch 7, Loss: 0.016620375216007233, Accuracy: 99.45999908447266, Test Loss: 0.034096963703632355, Test Accuracy: 98.8699951171875\n",
      "Running time:  123.28082036972046 seconds\n",
      "Epoch 8, Loss: 0.012628892436623573, Accuracy: 99.5633316040039, Test Loss: 0.03772752732038498, Test Accuracy: 98.90999603271484\n",
      "Running time:  125.64912104606628 seconds\n",
      "Epoch 9, Loss: 0.010629063472151756, Accuracy: 99.63166809082031, Test Loss: 0.04126139357686043, Test Accuracy: 98.95999908447266\n",
      "Running time:  124.69679403305054 seconds\n",
      "Epoch 10, Loss: 0.008195683360099792, Accuracy: 99.7300033569336, Test Loss: 0.05480772256851196, Test Accuracy: 98.66999816894531\n",
      "Running time:  125.09954476356506 seconds\n"
     ]
    }
   ],
   "source": [
    "# 數學系 大學部 3B 108201202 謝佳穎\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras import Model\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train.shape, y_train.shape\n",
    "x_test.shape, y_test.shape\n",
    "y_train\n",
    "x_train.min(), x_train.max()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train.min(), x_train.max()\n",
    "# Add a \"channels\" dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "x_train.shape  # x_test.shape\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "train_ds\n",
    "class MyModel(Model):   # tf.keras.Model class\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, (3,3), activation='relu')    # tf.keras.layers.Conv2D() 第一層\n",
    "        self.batchnorm1 = BatchNormalization()\n",
    "        self.conv2 = Conv2D(64,(3,3))                        # tf.keras.layers.Conv2D() 第二層\n",
    "        self.batchnorm2 = BatchNormalization()\n",
    "        self.conv3 = Conv2D(128,(3,3))                       # tf.keras.layers.Conv2D() 第三層\n",
    "        self.batchnorm3 = BatchNormalization()\n",
    "        self.maxpool = MaxPooling2D((2,2))                   #maxpool\n",
    "        self.flatten = Flatten()                             # tf.keras.layers.Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')              # tf.keras.layers.Dense()\n",
    "        self.batchnorm4 = BatchNormalization()               # tf.keras.layers.BatchNormalization()\n",
    "        self.d2 = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)                                    #Conv      第一層\n",
    "        x = self.batchnorm1(x)                               #batchnorm 第一層\n",
    "        x = self.conv2(x)                                    #Conv      第二層\n",
    "        x = self.batchnorm2(x)                               #batchnorm 第二層\n",
    "        x = self.conv3(x)                                    #Conv      第三層\n",
    "        x = self.batchnorm3(x)                               #batchnorm 第三層\n",
    "        x = self.maxpool(x)                                  #maxpool\n",
    "        x = self.flatten(x)                                  #flatten\n",
    "        x = self.d1(x)                                       #\n",
    "        x = self.batchnorm4(x)                               #\n",
    "        return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()\n",
    "model\n",
    "#  < tf.keras.losses.SparseCategoricalCrossentropy >\n",
    "#    from_logits: Whether y_pred is expected to be a logits tensor. \n",
    "#                 By default, we assume that y_pred encodes \n",
    "#                 a probability distribution. \n",
    "#   [Note]: Using from_logits=True may be more numerically stable.\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "@tf.function\n",
    "def train_step(images, labels):    # images : x_train , labels : y_train\n",
    "    ## ----------------------------------------------------------------------\n",
    "    ##  Forward propagation - \n",
    "    ##    tf.GradientTape()可以用在 training loop 裡，記錄並建構正向傳播的計算圖\n",
    "    ## ----------------------------------------------------------------------\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "\n",
    "    ## ----------------------------------------------------------------------\n",
    "    ##  Backpropagation - \n",
    "    ##    在完成“記錄”後，tf.GradientTape() 的 tape 物件則呼叫 gradient()方法，\n",
    "    ##    並傳入損失值 (loss score) 和模型可訓練的參數。 [from Ref 3.]\n",
    "    ## ----------------------------------------------------------------------\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    ## ----------------------------------------------------------------------\n",
    "    ##  Parameters' update - \n",
    "    ##    一旦計算出了梯度後，立即呼叫 optimizer.apply_gradients() 方法，\n",
    "    ##    傳入一個 list of tuple，每一個 tuple 的第二個則是參數變數，\n",
    "    ##    而第一個變數為針對該參數所計算出的梯度。 [from Ref 3.]\n",
    "    ## ----------------------------------------------------------------------    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "log_directory = 'logs/CNN_MNIST_BN/'\n",
    "train_log_dir = log_directory + current_time + '/train'\n",
    "test_log_dir = log_directory + current_time + '/test'\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start=time.time()\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "        \n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "    end=time.time()\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()*100))\n",
    "    print(\"Running time: \", str(end-start), \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9afd3253101e30c074f19e3615574f118d414e5211ab5a754e65723fada7756"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
