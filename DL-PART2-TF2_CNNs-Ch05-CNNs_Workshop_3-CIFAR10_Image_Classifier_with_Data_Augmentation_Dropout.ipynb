{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCN4NJHYUj6c"
   },
   "source": [
    "# < Deep Learning - PART2 TF2 CNNs >\n",
    "\n",
    "# Ch 5. CNNs Workshop 3 - CIFAR10 : Image Classifier with Data Augmentation & Dropout\n",
    "2021/10/01\n",
    "\n",
    "\n",
    "**[ Reference ] :**\n",
    "+ Keras Documentation : **Train a simple deep CNN on the CIFAR10 small images dataset** https://keras.io/examples/cifar10_cnn/\n",
    "+ **CIFAR-10 and CIFAR-100 datasets** https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "+ 李飛飛教授：Convolutional Neural Networks (CNNs / ConvNets)\n",
    "  (https://cs231n.github.io/convolutional-networks/)\n",
    "+ `tf.keras.layers.Conv2D`\n",
    "  (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "  \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oHQZ_-IUj6f"
   },
   "source": [
    "### [ NOTE ] :  Running the following code on Google Colab with GPU !!\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Vc46Z4HVe0r"
   },
   "source": [
    "## Running TensorFlow 2.0 on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "P7dmcl30Uj6f",
    "outputId": "331fc3eb-d9e1-47e9-a619-caca3d00e9fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vYKDxX9rUj6j"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZpZ2VbQUj6k"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4dIBi7ZUj6m"
   },
   "source": [
    "## Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "TbBYw0CaUj6n",
    "outputId": "d4e6adb1-7ff4-44da-ad0b-e7f2e7e7ea57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTM_FVoGUj6q"
   },
   "source": [
    "## Forward Propagation\n",
    "+ **Building a training model with `tf.keras`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmpLb1mrUj6r"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llQrfBlWUj6t"
   },
   "source": [
    "## Backpropagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzqpAWjHUj6u"
   },
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgV05HWlUj6y"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rV0oJYU1Uj6y"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaFyLnANUj61"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IDcEpsC1Uj61",
    "outputId": "869b6126-9db6-40e7-897d-2cd94c4de36b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:From <ipython-input-8-58db1f5097ea>:49: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1563 steps, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.8522 - accuracy: 0.3156 - val_loss: 1.5686 - val_accuracy: 0.4282\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.5820 - accuracy: 0.4212 - val_loss: 1.3962 - val_accuracy: 0.4895\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.4621 - accuracy: 0.4668 - val_loss: 1.2855 - val_accuracy: 0.5424\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.3848 - accuracy: 0.5029 - val_loss: 1.3087 - val_accuracy: 0.5283\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.3199 - accuracy: 0.5261 - val_loss: 1.1952 - val_accuracy: 0.5807\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.2646 - accuracy: 0.5492 - val_loss: 1.0823 - val_accuracy: 0.6243\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 1.2151 - accuracy: 0.5705 - val_loss: 1.0979 - val_accuracy: 0.6160\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1746 - accuracy: 0.5853 - val_loss: 1.0508 - val_accuracy: 0.6367\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1351 - accuracy: 0.6001 - val_loss: 0.9939 - val_accuracy: 0.6555\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1063 - accuracy: 0.6082 - val_loss: 1.0137 - val_accuracy: 0.6450\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 1.0778 - accuracy: 0.6211 - val_loss: 0.9684 - val_accuracy: 0.6643\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.0528 - accuracy: 0.6297 - val_loss: 0.9301 - val_accuracy: 0.6730\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 1.0243 - accuracy: 0.6415 - val_loss: 0.9945 - val_accuracy: 0.6649\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.0060 - accuracy: 0.6457 - val_loss: 0.8892 - val_accuracy: 0.6916\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9801 - accuracy: 0.6570 - val_loss: 0.8424 - val_accuracy: 0.7071\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9681 - accuracy: 0.6589 - val_loss: 0.8317 - val_accuracy: 0.7079\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9542 - accuracy: 0.6675 - val_loss: 0.8605 - val_accuracy: 0.6934\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9347 - accuracy: 0.6730 - val_loss: 0.8303 - val_accuracy: 0.7125\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9208 - accuracy: 0.6768 - val_loss: 0.7733 - val_accuracy: 0.7314\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9115 - accuracy: 0.6806 - val_loss: 0.8550 - val_accuracy: 0.7100\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9024 - accuracy: 0.6855 - val_loss: 0.7837 - val_accuracy: 0.7230\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8937 - accuracy: 0.6900 - val_loss: 0.7865 - val_accuracy: 0.7286\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8833 - accuracy: 0.6945 - val_loss: 0.7812 - val_accuracy: 0.7257\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8740 - accuracy: 0.6971 - val_loss: 0.7955 - val_accuracy: 0.7253\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8716 - accuracy: 0.6961 - val_loss: 0.7891 - val_accuracy: 0.7319\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8597 - accuracy: 0.7020 - val_loss: 0.7382 - val_accuracy: 0.7421\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8568 - accuracy: 0.7059 - val_loss: 0.7289 - val_accuracy: 0.7510\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8541 - accuracy: 0.7052 - val_loss: 0.7725 - val_accuracy: 0.7366\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8476 - accuracy: 0.7087 - val_loss: 0.7659 - val_accuracy: 0.7441\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8410 - accuracy: 0.7123 - val_loss: 0.7346 - val_accuracy: 0.7480\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8377 - accuracy: 0.7139 - val_loss: 0.7613 - val_accuracy: 0.7409\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8360 - accuracy: 0.7144 - val_loss: 0.7264 - val_accuracy: 0.7492\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8283 - accuracy: 0.7155 - val_loss: 0.7821 - val_accuracy: 0.7365\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8243 - accuracy: 0.7176 - val_loss: 0.7258 - val_accuracy: 0.7615\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8299 - accuracy: 0.7177 - val_loss: 0.7439 - val_accuracy: 0.7461\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.8227 - accuracy: 0.7201 - val_loss: 0.7150 - val_accuracy: 0.7599\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8220 - accuracy: 0.7201 - val_loss: 0.7034 - val_accuracy: 0.7635\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8213 - accuracy: 0.7209 - val_loss: 0.7193 - val_accuracy: 0.7582\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8152 - accuracy: 0.7207 - val_loss: 0.7304 - val_accuracy: 0.7671\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8172 - accuracy: 0.7227 - val_loss: 0.7036 - val_accuracy: 0.7684\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8120 - accuracy: 0.7248 - val_loss: 0.6881 - val_accuracy: 0.7684\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8116 - accuracy: 0.7257 - val_loss: 0.7248 - val_accuracy: 0.7570\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8085 - accuracy: 0.7258 - val_loss: 0.7283 - val_accuracy: 0.7587\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8088 - accuracy: 0.7257 - val_loss: 0.7152 - val_accuracy: 0.7633\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8068 - accuracy: 0.7241 - val_loss: 0.7186 - val_accuracy: 0.7553\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8049 - accuracy: 0.7264 - val_loss: 0.7038 - val_accuracy: 0.7662\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8063 - accuracy: 0.7248 - val_loss: 0.7500 - val_accuracy: 0.7517\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.7995 - accuracy: 0.7315 - val_loss: 0.6898 - val_accuracy: 0.7786\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.8005 - accuracy: 0.7287 - val_loss: 0.7452 - val_accuracy: 0.7496\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.8020 - accuracy: 0.7296 - val_loss: 0.7083 - val_accuracy: 0.7645\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHChiTyFUj64"
   },
   "source": [
    "## Saving the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cKwN7UUeUj64",
    "outputId": "6acf88f0-7618-4ef3-ec93-340362c0d8e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBLLhR2KUj67"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "no43mz5sUj67",
    "outputId": "4bcc09de-ee75-4831-cdd0-6e2b6a2b8d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.7083 - accuracy: 0.7645\n",
      "Test loss: 0.708253707408905\n",
      "Test accuracy: 0.7645\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DL_CNNs-Ch02-CNNs_Workshop_2-CIFAR10_Image_Classifier_with_Data_Augmentation_Dropout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
