{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Deep Learning - PART1 TF2 Basics >\n",
    "# Ch 2. Workshop - Intro to TensorFlow 2.0 Programming\n",
    "2021/10/01\n",
    "\n",
    "**[ Reference ]**\n",
    "1. TensorFlow Core - Tutorials : **`TensorFlow 2 quickstart for experts`**, 2019. https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "2. TensorFlow Core - Guides : **`Better performance with tf.function and AutoGraph`** https://www.tensorflow.org/guide/function\n",
    "3. 程式前沿, **`Python裝飾器的函數語言程式設計詳解`** https://codertw.com/%e7%a8%8b%e5%bc%8f%e8%aa%9e%e8%a8%80/372927/\n",
    "4. **`TensorFlow2基础操作篇：创建Tensor`** https://zhuanlan.zhihu.com/p/68223806\n",
    "5. **`tf.function 和 Autograph使用指南-Part 3`** https://zhuanlan.zhihu.com/p/68279357"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Content >\n",
    "+ [1. Running TensorFlow 2 quickstart for experts](#TF2advanced)\n",
    "\n",
    "\n",
    "+ [2. TensorFlow 2.0 Programming Related](#TF2programming)\n",
    "    + [2.1 `tf.data.Dataset`](#tf.data.Dataset)\n",
    "    + [2.2 `tf.keras`](#tf.keras)\n",
    "    + [2.3 Computational Graph for Neural Networks](#Computational_Graph)\n",
    "    \n",
    "    \n",
    "+ [3. More on `tf.function` & `AutoGraph`](#autograph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "<a id='TF2advanced'></a>\n",
    "## 1. Running `TensorFlow 2 quickstart for experts`\n",
    "+ `advanced.ipynb` on Colab : https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "\n",
    "> Additional tutorials:\n",
    "\n",
    "> + **`tf.Tensor`** -\n",
    "    - A Tensor is a multi-dimensional array. \n",
    "    - Similar to NumPy ndarray objects, `tf.Tensor` objects have a data type and a shape. \n",
    "    - Additionally, `tf.Tensor`s can reside in accelerator memory (like a GPU). \n",
    "    - TensorFlow offers a rich library of operations (`tf.add`, `tf.matmul`, `tf.linalg.inv` etc.) that consume and produce `tf.Tensor`s. These operations automatically convert native Python types.\n",
    "> + `Customization basics: tensors and operations`** - **`tf.Tensor`**  https://www.tensorflow.org/tutorials/customization/basics\n",
    "\n",
    "> + `Distributed training with Keras` https://www.tensorflow.org/tutorials/distribute/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "<a id='TF2programming'></a>\n",
    "## 2. TensorFlow 2.0 Programming Related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tf.data.Dataset'> </a>\n",
    "### 2.1 **`tf.data.Dataset`** \n",
    "> https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "> `Class` **`Dataset`** \n",
    "        - Represents a potentially large set of elements.\n",
    "\n",
    "> **Use `tf.data` to batch and shuffle the dataset**:\n",
    ">\n",
    "> For example :\n",
    ">\n",
    "> `train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "                      .shuffle(10000).batch(32)`\n",
    "\n",
    "> [ NOTE ]:\n",
    "> + `tf.data.Dataset.from_tensor_slices` - https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices\n",
    "> + `shuffle()` - https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#shuffle\n",
    "> + `batch()` - https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tf.keras'> </a>\n",
    "### 2.2 **`tf.keras`** \n",
    " + **`tf.keras`** is *TensorFlow's high-level API for building and training deep learning models*.\n",
    ">   + Module: `tf.keras`- https://www.tensorflow.org/api_docs/python/tf/keras\n",
    ">   + Subclass: `Keras` - https://www.tensorflow.org/guide/keras#model_subclassing\n",
    "\n",
    "+ **3 key advantages**:\n",
    "> + *User-friendly*\n",
    "> + *Modular and composable*\n",
    "> + *Easy to extend* \n",
    "\n",
    "> **[Starter Tutorials for `tf.keras`]** :\n",
    "> + `Basic classification: Classify images of clothing` https://www.tensorflow.org/tutorials/keras/classification\n",
    "> + `Text classification with TensorFlow Hub: Movie reviews` https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n",
    "> + `Text classification with preprocessed text: Movie reviews` https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "> + `Basic regression: Predict fuel efficiency` https://www.tensorflow.org/tutorials/keras/regression\n",
    "> + `Explore overfit and underfit` https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\n",
    "> + `Save and load models` https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.keras.losses.SparseCategoricalCrossentropy()`** : https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n",
    "> + **Class `SparseCategoricalCrossentropy`** - Computes the crossentropy loss between the labels and predictions.\n",
    "> + **Use this crossentropy loss function when there are two or more label classes.**\n",
    "> + **We expect labels to be provided as integers.** \n",
    "    \n",
    "    > + **If you want to provide labels using `one-hot` representation, please use `CategoricalCrossentropy` loss.**\n",
    "    \n",
    "    > + There should be `# classes` floating point values per feature for `y_pred` and a single floating point value per feature for `y_true`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Module: **`tf.keras.metrics`**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
    "> **Built-in metrics classes** : (*to name a few*)\n",
    "    + **`class SparseCategoricalAccuracy`** : Calculates how often predictions matches integer labels. https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy\n",
    "    + **`class CategoricalAccuracy`** : Calculates how often predictions matches labels.\n",
    "    + **`class Mean`** : Computes the (weighted) mean of the given values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Computational_Graph'> </a>\n",
    "### 2.3 Computational Graph for Neural Networks\n",
    "\n",
    "> + **[Ref]: YouTube - `MLwPython_Lecture 01 - Perceptron, Logistic Regression & Neural Networks`**,https://youtu.be/6AWs76fsKo4\n",
    ">     + **[PPT & Code]:** https://drive.google.com/drive/folders/10AwHPBLsCFnWMCav5GCvoJ3eNqPoYctg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Fig_1-Graph_Theory_Neural_Networks.png\" width='600' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Fig_2a-Computation_Graph-Forward_Propagation.png\" width='600' />\n",
    "\n",
    "<img src=\"figures/Fig_2b-Computation_Graph-Back-Propagation.png\" width='600' />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`@tf.function`** Decorator ：一種 Python 函數語言程式設計的技巧。\n",
    "\n",
    "> **[ REFERENCE ]** : \n",
    "> \n",
    ">    2.1 TensorFlow Core - Guides : **`Better performance with tf.function and AutoGraph`** https://www.tensorflow.org/guide/function\n",
    ">\n",
    ">    2.2 程式前沿, **`Python裝飾器的函數語言程式設計詳解`** https://codertw.com/%e7%a8%8b%e5%bc%8f%e8%aa%9e%e8%a8%80/372927/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "**Decorator 的本質** : ( from **Ref. 2.2** )\n",
    "\n",
    "     當你用一個 @decorator 來修飾某個函式 func 時，如下所示:\n",
    "        @decorator\n",
    "        def func():\n",
    "            pass\n",
    "\n",
    "     其直譯器會解析成下面這樣的語句：\n",
    "\n",
    "        func = decorator(func)\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@hello: foo() \n",
      "\n",
      "Calling foo()... \n",
      "\n",
      "hello, foo\n",
      "i am foo\n",
      "goodby, foo\n"
     ]
    }
   ],
   "source": [
    "# Example from 程式前沿, \"Python裝飾器的函數語言程式設計詳解\" \n",
    "# https://codertw.com/%e7%a8%8b%e5%bc%8f%e8%aa%9e%e8%a8%80/372927/\n",
    "\n",
    "def hello(fn):\n",
    "    def wrapper():\n",
    "        print(\"hello, %s\" % fn.__name__)\n",
    "        fn()\n",
    "        print(\"goodby, %s\" % fn.__name__)\n",
    "    return wrapper\n",
    "\n",
    "print('@hello: foo() \\n')\n",
    "\n",
    "@hello        # foo = hello(foo)\n",
    "def foo():\n",
    "    print(\"i am foo\")\n",
    "\n",
    "print('Calling foo()... \\n')\n",
    "foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "### **`AutoGraph`** \n",
    " - `AutoGraph`是 TF 提供的一個非常具有前景的工具,它能夠將一部分 python 語法的代碼轉譯成高效的圖表示代碼.\n",
    " - 由於從 `TF 2.0` 開始, TF 將會預設使用動態圖(`eager execution`),因此利用`AutoGraph`, 在理想情況下 ,能讓我們方便、靈活使用動態圖撰寫程式,同時利用靜態圖方式高效、穩定執行程式。\n",
    "\n",
    "> **[ REFERENCE ]** : \n",
    ">\n",
    ">    + TensorFlow Core - Guides : **`Better performance with tf.function and AutoGraph`** https://www.tensorflow.org/guide/function)\n",
    ">\n",
    ">    + NLPer, 機器學習谷歌開發者專家, **`tf.function和Autograph使用指南-Part 1`** https://zhuanlan.zhihu.com/p/67192636\n",
    ">\n",
    ">    + Github, **TensorFlow 2.0: Functions, not Sessions.** https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md\n",
    ">\n",
    ">    + TensorFlow - Guides : **`Keras and AutoGraph`** https://www.tensorflow.org/guide/function#keras_and_autograph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + `TF2.0` 的**其中一個重要改變就是去除 `TF 1.x` 版本的 `tf.Session`**.\n",
    "+ 這個改變會使得開發者採用更好的方式來撰寫程式 : 不必再用 `tf.Session` 來執行 `TF` 程式，只需要在一個 python 函數，加上一個簡單的 裝飾器 (decorator) 即可。\n",
    "\n",
    "> + 在 `TF2.0` 裡面，**如果需要構建計算圖，我們只需要給 python 函數加上 `@tf.function` 的裝飾器**.\n",
    "\n",
    "> + **這個自動將python代碼轉成圖表示代碼的工具就叫做AutoGraph**.\n",
    "+ 在 `TF2.0` 中，如果一個函數被 **`@tf.function`** 裝飾了，那麼 **`AutoGraph`** 將會被自動調用，從而將 python 函數轉換成可執行的圖表示."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='autograph'></a>\n",
    "## 3. More on `tf.function` & `AutoGraph`\n",
    "> ###  TensorFlow Core - Guide :  \"Better performance with tf.function and AutoGraph\"\n",
    "https://www.tensorflow.org/guide/function#keras_and_autograph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "Q: Is Eager Execution active? A: True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "\n",
    "# Checking Eager Execution mode...\n",
    "print('Q: Is Eager Execution active? A: {}'.format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "a = 2\n",
      "tf.Tensor(-2, shape=(), dtype=int32)\n",
      "f = -2\n"
     ]
    }
   ],
   "source": [
    "# Building a computation graph...\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = tf.constant(5)\n",
    "\n",
    "d = tf.multiply(a, b)\n",
    "e = tf.add(b, c)\n",
    "f = tf.subtract(d, e)\n",
    "\n",
    "# Launching the computation graph dynamically with Eager Execution.\n",
    "print(a)\n",
    "print('a = {}'.format(a))\n",
    "print(f)\n",
    "print('f = {}'.format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `tf.function` decorator\n",
    "\n",
    "> + When you annotate a function with **`tf.function`**, you can still call it like any other function. \n",
    "+ **But `tf.function` will be compiled into a graph**, which means you get the benefits of faster execution, running on GPU or TPU, or exporting to SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :  tf.Tensor(\n",
      "[[0.77874935]\n",
      " [0.67371106]\n",
      " [0.09093118]], shape=(3, 1), dtype=float32)\n",
      "w :  tf.Tensor([[0.01682639 0.14035904 0.06817579]], shape=(1, 3), dtype=float32)\n",
      "b =  tf.Tensor([2.1116662], shape=(1,), dtype=float32)\n",
      "\n",
      "-----------\n",
      "Logit_Regress(w, x) = [[0.90251887]] \n",
      "\n",
      "tf.Tensor([[0.90251887]], shape=(1, 1), dtype=float32)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40, shape=(1, 1), dtype=float32, numpy=array([[0.90251887]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def Logit_Regress(w, x):\n",
    "  return tf.nn.sigmoid(tf.matmul(w, x)+b)\n",
    "\n",
    "w = tf.random.uniform((1, 3))\n",
    "x = tf.random.uniform((3, 1))\n",
    "b = tf.random.uniform((1,), minval=2, maxval=3)\n",
    "\n",
    "print('x : ', x)\n",
    "print('w : ', w)\n",
    "print('b = ', b)\n",
    "print('\\n-----------')\n",
    "\n",
    "print('Logit_Regress(w, x) = {} \\n'.format(Logit_Regress(w, x)))\n",
    "print(Logit_Regress(w, x))\n",
    "print('-----------')\n",
    "Logit_Regress(w, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + **If we examine the result of the annotation, we can see that it's a special callable that handles all interactions with the TensorFlow runtime.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x2017c094ec8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logit_Regress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + #### If your code uses multiple functions, you don't need to annotate them all - any functions called from an annotated function will also run in graph mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=52, shape=(3,), dtype=int32, numpy=array([3, 5, 7])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_layer(x):\n",
    "  return 2 * x + 1\n",
    "\n",
    "@tf.function\n",
    "def deep_net(x):\n",
    "  return tf.nn.relu(linear_layer(x))\n",
    "\n",
    "deep_net(tf.constant((1, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + #### Functions can be faster than eager code, for graphs with many small ops. But for graphs with a few expensive ops (like convolutions), you may not see much speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 1.1287187000000003\n",
      "Function conv: 1.101934400000001\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit   # This module provides a simple way to time small bits of Python code.\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)  # 2D Convolution Layers\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "    return conv_layer(image)\n",
    "\n",
    "# 4D-Tensor:(samples, height, width, channels)\n",
    "image = tf.zeros([1, 200, 200, 100]) \n",
    "\n",
    "# warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager lstm: 0.026034899999999084\n",
      "function lstm: 0.004357699999999909\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------\n",
    "# Long-Short-Term-Memory (LSTM) model - one of the RNNs\n",
    "# LSTMCell - This class processes one step within the whole time sequence input, \n",
    "#            whereas tf.keras.layer.LSTM processes the whole sequence.\n",
    "#-------------------------------------------\n",
    "lstm_cell = tf.keras.layers.LSTMCell(10) \n",
    "\n",
    "@tf.function\n",
    "def lstm_fn(input, state):\n",
    "    return lstm_cell(input, state)\n",
    "\n",
    "input = tf.ones([10, 10])\n",
    "state = [tf.ones([10, 10])] * 2\n",
    "\n",
    "# warm up\n",
    "lstm_cell(input, state); lstm_fn(input, state)\n",
    "print(\"eager lstm:\", timeit.timeit(lambda: lstm_cell(input, state), number=10))\n",
    "print(\"function lstm:\", timeit.timeit(lambda: lstm_fn(input, state), number=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python control flow\n",
    "\n",
    "> + When using data-dependent control flow inside `tf.function`, you can use Python control flow statements and AutoGraph will convert them into appropriate TensorFlow ops. For example, `if` statements will be converted into `tf.cond()` if they depend on a `Tensor`.\n",
    "+ In the example below, `x` is a `Tensor` but the `if` statement works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square_if_positive(2) = 4\n",
      "square_if_positive(-2) = 0\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "    if x > 0:\n",
    "        x = x * x\n",
    "    else:\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
    "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + #### AutoGraph supports common Python statements like `while`, `for`, `if`, `break`, `continue` and `return`, with support for nesting. \n",
    "+ That means you can use `Tensor` expressions in the condition of `while` and `if` statements, or iterate over a `Tensor` in a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=619, shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def sum_even(items):\n",
    "    s = 0\n",
    "    for c in items:\n",
    "        if c % 2 > 0:\n",
    "            continue\n",
    "        s += c\n",
    "    return s\n",
    "\n",
    "sum_even(tf.constant([10, 12, 15, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + #### AutoGraph also provides a low-level API for advanced users. \n",
    "\n",
    "**For example we can use it to have a look at the generated code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__sum_even(items):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('sum_even', 'sum_even_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as sum_even_scope:\n",
      "    s = 0\n",
      "\n",
      "    def get_state_2():\n",
      "      return ()\n",
      "\n",
      "    def set_state_2(_):\n",
      "      pass\n",
      "\n",
      "    def loop_body(iterates, s):\n",
      "      c = iterates\n",
      "      continue_ = False\n",
      "\n",
      "      def get_state():\n",
      "        return ()\n",
      "\n",
      "      def set_state(_):\n",
      "        pass\n",
      "\n",
      "      def if_true():\n",
      "        continue_ = True\n",
      "        return continue_\n",
      "\n",
      "      def if_false():\n",
      "        return continue_\n",
      "      cond = c % 2 > 0\n",
      "      continue_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('continue_',), ())\n",
      "\n",
      "      def get_state_1():\n",
      "        return ()\n",
      "\n",
      "      def set_state_1(_):\n",
      "        pass\n",
      "\n",
      "      def if_true_1():\n",
      "        s_1, = s,\n",
      "        s_1 += c\n",
      "        return s_1\n",
      "\n",
      "      def if_false_1():\n",
      "        return s\n",
      "      cond_1 = ag__.not_(continue_)\n",
      "      s = ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1, ('s',), ())\n",
      "      return s,\n",
      "    s, = ag__.for_stmt(items, None, loop_body, get_state_2, set_state_2, (s,), ('s',), ())\n",
      "    do_return = True\n",
      "    retval_ = sum_even_scope.mark_return_value(s)\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(sum_even.python_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of more complicated control flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fizz\n",
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def fizzbuzz(n):\n",
    "    for i in tf.range(n):\n",
    "        if i % 3 == 0:\n",
    "            tf.print('Fizz')\n",
    "        elif i % 5 == 0:\n",
    "            tf.print('Buzz')\n",
    "        else:\n",
    "            tf.print(i)\n",
    "\n",
    "fizzbuzz(tf.constant(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Further Reading ] : Keras and AutoGraph\n",
    "> + Ref : \"`Keras and AutoGraph`\" https://www.tensorflow.org/guide/function#keras_and_autograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=727, shape=(2,), dtype=int32, numpy=array([-1, -2])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(tf.keras.models.Model):\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_data):\n",
    "        if tf.reduce_mean(input_data) > 0:\n",
    "            return input_data\n",
    "        else:\n",
    "            return input_data // 2\n",
    "\n",
    "\n",
    "model = CustomModel()\n",
    "\n",
    "model(tf.constant([-2, -4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
